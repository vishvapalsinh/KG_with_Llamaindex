{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ollama.generate(model='deepseek-r1:1.5b', prompt='What is quantum physics?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'ollama._types.GenerateResponse'>\n"
     ]
    }
   ],
   "source": [
    "print(type(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Quantum physics, also known as quantum mechanics or quantum physics, is the fundamental theory in theoretical physics that describes the behavior of nature at the smallest scale of either usable matter and energy. It explains the phenomena associated with discrete quantities like angular momentum, spin, electric charge, and the structure of atoms.\n",
      "\n",
      "### Key Concepts:\n",
      "1. **Wave-Particle Duality**: Every particle or quantum entity can be described as both a particle and a wave. For example, electrons can exhibit both particle-like properties (such as in the double-slit experiment) and wave-like properties (such as in diffraction patterns).\n",
      "\n",
      "2. **Quantization of Energy**: Energy can only take on certain discrete values. This means that objects with small masses cannot have arbitrarily low kinetic energy because these energies correspond to photon-like energies, not necessarily infinite divisibility.\n",
      "\n",
      "3. **Superposition**: A key principle of quantum mechanics states that a physical system doesn't have multiple possible states simultaneously. The state of a quantum system is described by an infinite set of possibilities (the wavefunction), and only one possibility is determined when measurement occurs.\n",
      "\n",
      "4. **Entanglement**: This phenomenon, where particles become interconnected such that the state of one particle is directly connected to another, no matter the distance separating them, challenges classical intuitions about locality and realism.\n",
      "\n",
      "5. **Quantum Entanglement**: When two particles are entangled, their quantum states become correlated in a way that can't be explained by classical physics alone. This effect has been experimentally verified and is central to many areas of quantum technology, including quantum computing and quantum cryptography.\n",
      "\n",
      "6. **Uncertainty Principle**: As discovered by Werner Heisenberg, it's impossible to simultaneously know both the exact position and momentum of a particle. The more precisely one value is measured, the less precisely the other can be known.\n",
      "\n",
      "### Mathematical Framework:\n",
      "Quantum mechanics is described using mathematical models such as wave functions (which provide information about the probabilities of various outcomes) and operators that describe physical quantities. The most famous equation in quantum mechanics is Schrödinger's equation, which describes how a quantum system evolves over time.\n",
      "\n",
      "7. **Wave Function**: This is the fundamental concept used to describe the state of a quantum system. It provides the complete information about the system, including all possible states and their probabilities.\n",
      "\n",
      "8. **Hilbert Space**: A type of vector space used in quantum mechanics to describe the state space of a system. Each vector in this space represents a possible quantum state of the system.\n",
      "\n",
      "9. **Operators and Observables**: Physical quantities (like position, momentum, energy) are represented by operators in quantum mechanics. The eigenvalues of these operators correspond to the possible measured values of the corresponding physical quantity.\n",
      "\n",
      "10. **Measurement Problem**: This is the question of how exact properties of a quantum system can be found when only approximate values can be obtained upon measurement. This has led to various interpretations of quantum mechanics, such as the Copenhagen interpretation, the wavefunction measurement hypothesis, and others.\n",
      "\n",
      "### Applications:\n",
      "Quantum physics has numerous applications across various fields, including:\n",
      "\n",
      "- **Semiconductor Physics**: The foundation of modern electronics.\n",
      "- **Optics**: Quantum phenomena are essential in technologies like lasers, superconductors, and quantum computing.\n",
      "- **Chemistry**: Fundamental to understanding molecular structure and reactions.\n",
      "- **Relativity**: Quantum mechanics complements Einstein's theory of relativity, leading to concepts like quantum gravity.\n",
      "\n",
      "### Broader Context:\n",
      "Quantum physics is a cornerstone of modern science and technology. It also continues to be an area of active research, with ongoing developments such as quantum computing, quantum information theory, and the exploration of quantum gravity.\n"
     ]
    }
   ],
   "source": [
    "print(response['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.llms import ollama\n",
    "from langchain import LLMChain, PromptTemplate\n",
    "from langchain.llms import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Partial functions in Python are functions that only take some of the required arguments, allowing for flexible function composition.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ollama.Ollama(model='llama3:latest')\n",
    "llm.invoke('Tell me about partial functions in python in 20 words or less')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In Python, partial functions allow fixing some arguments of a function, creating a new function with reduced argumentality.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ollama.Ollama(model='qwen2')\n",
    "llm.invoke('Tell me about partial functions in python in 20 words or less')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepseek = ollama.Ollama(model='deepseek-r1:1.5b')\n",
    "lamma3 = ollama.Ollama(model='llama3:latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the system role and prompt template\n",
    "system_role = \"\"\"\n",
    "You are a column property annotator and find the relation between column 1 and column 3 for the table format data.\n",
    "Just tell me one of the following labels without giving any explanation.\n",
    "The Labels are:\n",
    "'publicationDate', 'price', 'language', 'currency', 'publisher', 'author', 'numberOfPages', 'isbn', 'format', 'genre', 'review',\n",
    "'rating', 'image', 'description', 'startDateTime', 'endDateTime', 'locationName', 'performer', 'address', 'category', \n",
    "'albumRuntime', 'time', 'city', 'country', 'region', 'postalCode', 'title', 'employer', 'day', 'director', 'starring', \n",
    "'productionCompany', 'totalTracks', 'artist', 'album', 'birthPlace', 'birthDate', 'nationality', 'gender', 'deathDate', \n",
    "'weight', 'colour', 'material', 'brand', 'manufacturer', 'releaseDate', 'cuisine', 'episodeNumber', 'televisionSeries'\n",
    "\"\"\"\n",
    "\n",
    "# Define the user input (table data)\n",
    "table_data = \"\"\"\n",
    "column 1,   column 2,   column 3,   column 4\n",
    "9789722539739,\tA Cidade Perdida,\t728,\t2020-07-10\n",
    "9789722531924,\tA Cúpula - livro 1,\t704,\t2016-04-08\n",
    "9789722527118,\tMisery,\t480,\t2013-09-13\n",
    "9789722532457,\tA Cúpula - Livro 2,\t656,\t2016-08-05\n",
    "9789722537636,\tO Olho de Deus,\t528,\t2019-05-10\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt template\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"table_data\"],\n",
    "    template=f\"\"\"\n",
    "    {system_role}\n",
    "\n",
    "    Analyze the following table data and determine the relationship between column 1 and column 3.\n",
    "    Return only one of the predefined labels without any explanation or elaboration or thinking process. I just need one label.\n",
    "\n",
    "    Table Data:\n",
    "    {table_data}\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the LLMChain\n",
    "chain = LLMChain(llm=deepseek, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the chain\n",
    "response = chain.run(table_data=table_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the response\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain1 = LLMChain(llm=lamma3, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "response1 = chain1.run(table_data=table_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'isbn'\n"
     ]
    }
   ],
   "source": [
    "print(response1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a sample file and sources residing in it : File name and data residing in it. \n",
    "file_path_gz = 'C:/Research/Uni_SoSe23/semtab2023/dataset/Round2-SOTAB-CPA-Tables/Round2-SOTAB-CPA-Tables/Book_11x17.pt_September2020_CPA.json.gz'  # Replace with the actual file path of your JSON file\n",
    "df = pd.read_json(file_path_gz, lines=True, compression='gzip')\n",
    "df_sample = df.sample(n=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                0              1    2           3\n",
      "27                    The Shining  9789722531696  632  2017-01-13\n",
      "16                      Despertar  9789722537780  464  2019-06-07\n",
      "12             O Advogado Mafioso  9789722538572  512  2019-08-02\n",
      "22            A História de Lisey  9789722534956  672  2018-01-12\n",
      "8                    Fim de Turno  9789722539852  480  2020-09-18\n",
      "9   Mude de Cérebro, Mude de Vida  9789722536288  464  2018-05-18\n",
      "21                 Chegada a Hora  9789722539838  552  2020-08-14\n",
      "0                A Cidade Perdida  9789722539739  728  2020-07-10\n",
      "26     De Mãos Dadas com os Anjos  9789722539845  392  2020-08-01\n",
      "13             A Colónia do Diabo  9789722528603  624  2014-07-11\n"
     ]
    }
   ],
   "source": [
    "# df.head()\n",
    "print(df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to a string representation (tabular format)\n",
    "def dataframe_to_string(df):\n",
    "    \"\"\"Convert Pandas DataFrame to a tabular string format.\"\"\"\n",
    "    table_str = df.to_csv(index=False, sep=\",\")  # Use comma-space for readability\n",
    "    return table_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_data_c = dataframe_to_string(df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,1,2,3\n",
      "The Shining,9789722531696,632,2017-01-13\n",
      "Despertar,9789722537780,464,2019-06-07\n",
      "O Advogado Mafioso,9789722538572,512,2019-08-02\n",
      "A História de Lisey,9789722534956,672,2018-01-12\n",
      "Fim de Turno,9789722539852,480,2020-09-18\n",
      "\"Mude de Cérebro, Mude de Vida\",9789722536288,464,2018-05-18\n",
      "Chegada a Hora,9789722539838,552,2020-08-14\n",
      "A Cidade Perdida,9789722539739,728,2020-07-10\n",
      "De Mãos Dadas com os Anjos,9789722539845,392,2020-08-01\n",
      "A Colónia do Diabo,9789722528603,624,2014-07-11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(table_data_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Dynamic Prompt\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"table_data\"],\n",
    "    template=\"\"\"\n",
    "You are an expert in data annotation and schema inference. Your task is to analyze the given tabular data \n",
    "and determine the best relationships between the **first column (index 0) and each of the remaining columns (index 1,2,3, etc.)**.\n",
    "\n",
    "Strictly output only valid JSON without any additional explanations, comments, or formatting outside the JSON structure.\n",
    "\n",
    "## **Tabular Data (No Headers Provided)**\n",
    "Each row represents a real-world entity, and the first column (index 0) should be analyzed in relation to all other columns.\n",
    "\n",
    "{table_data}\n",
    "\n",
    "## **Task**\n",
    "- Identify the **best relationship** between **index 0** and each of the remaining indices (1,2,3, etc.).\n",
    "- Use **index-based references** instead of column names.\n",
    "- The relationship should be inferred from the data values and one of the following labels:\n",
    "\n",
    "'publicationDate', 'price', 'language', 'currency', 'publisher', 'author', 'numberOfPages', 'isbn', 'format', 'genre', \n",
    "'review', 'rating', 'image', 'description', 'startDateTime', 'endDateTime', 'locationName', 'performer', 'address', \n",
    "'category', 'albumRuntime', 'time', 'city', 'country', 'region', 'postalCode', 'title', 'employer', 'day', 'director', \n",
    "'starring', 'productionCompany', 'totalTracks', 'artist', 'album', 'birthPlace', 'birthDate', 'nationality', 'gender', \n",
    "'deathDate', 'weight', 'colour', 'material', 'brand', 'manufacturer', 'releaseDate', 'cuisine', 'episodeNumber', \n",
    "'televisionSeries'\n",
    "\n",
    "- Provide a structured JSON output as shown below:\n",
    "\n",
    "```json\n",
    "{{\n",
    "  \"Index 0 - Index 1\": {{\n",
    "    \"relationship\": \"Possible relationship inferred\"\n",
    "  }},\n",
    "  \"Index 0 - Index 2\": {{\n",
    "    \"relationship\": \"Another possible relationship\"\n",
    "  }},\n",
    "  ...\n",
    "}}```\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM (Llama 3 locally in Ollama)\n",
    "llm = Ollama(model=\"llama3:latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\anaconda3\\envs\\langchain_env\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "# chain = RunnableSequence([prompt_template, llm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\anaconda3\\envs\\langchain_env\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "response = chain.run(table_data=table_data_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the JSON output:\n",
      "```\n",
      "{\n",
      "  \"Index 0 - Index 1\": {\n",
      "    \"relationship\": \"isbn\"\n",
      "  },\n",
      "  \"Index 0 - Index 2\": {\n",
      "    \"relationship\": \"numberOfPages\"\n",
      "  },\n",
      "  \"Index 0 - Index 3\": {\n",
      "    \"relationship\": \"publicationDate\"\n",
      "  }\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set folder path\n",
    "folder_path = \"C:/Research/Uni_SoSe23/semtab2023/dataset/Round2-SOTAB-CPA-Tables/Round2-SOTAB-CPA-Tables/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Select 5 random JSON.GZ files\n",
    "num_files = 5\n",
    "num_rows = 10\n",
    "all_files = [f for f in os.listdir(folder_path) if f.endswith(\".json.gz\")]\n",
    "selected_files = random.sample(all_files, num_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt template\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"table_data\"],\n",
    "    template=\"\"\"\n",
    "You are an expert in data annotation and schema inference. Your task is to analyze the given tabular data \n",
    "and determine the best relationships between the **first column (index 0) and each of the remaining columns (index 1,2,3, etc.)**.\n",
    "\n",
    "## **Tabular Data (No Headers Provided)**\n",
    "Each row represents a real-world entity, and the first column (index 0) should be analyzed in relation to all other columns.\n",
    "\n",
    "{table_data}\n",
    "\n",
    "## **Task**\n",
    "- Identify the **best relationship** between **index 0** and each of the remaining indices (1,2,3, etc.).\n",
    "- Use **index-based references** instead of column names.\n",
    "- The relationship should be inferred from the data values and one of the following labels:\n",
    "\n",
    "'publicationDate', 'price', 'language', 'currency', 'publisher', 'author', 'numberOfPages', 'isbn', 'format', 'genre', \n",
    "'review', 'rating', 'image', 'description', 'startDateTime', 'endDateTime', 'locationName', 'performer', 'address', \n",
    "'category', 'albumRuntime', 'time', 'city', 'country', 'region', 'postalCode', 'title', 'employer', 'day', 'director', \n",
    "'starring', 'productionCompany', 'totalTracks', 'artist', 'album', 'birthPlace', 'birthDate', 'nationality', 'gender', \n",
    "'deathDate', 'weight', 'colour', 'material', 'brand', 'manufacturer', 'releaseDate', 'cuisine', 'episodeNumber', \n",
    "'televisionSeries'\n",
    "\n",
    "- Provide a structured JSON output as shown below:\n",
    "\n",
    "```json\n",
    "{{\n",
    "  \"Index 0 - Index 1\": {{\n",
    "    \"relationship\": \"Possible relationship inferred\"\n",
    "  }},\n",
    "  \"Index 0 - Index 2\": {{\n",
    "    \"relationship\": \"Another possible relationship\"\n",
    "  }},\n",
    "  ...\n",
    "}}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"llama3:latest\")\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_string(df): \n",
    "    \"\"\"Convert Pandas DataFrame to a structured tabular string format.\"\"\" \n",
    "    return df.to_csv(index=False, header=False, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is from chatgpt\n",
    "def extract_json_from_llm_response(response):\n",
    "    \"\"\"Extract JSON data from an LLM response that contains markdown code blocks.\"\"\"\n",
    "    json_pattern = r'```(?:json)?\\s*(.*?)\\s*```'\n",
    "    matches = re.findall(json_pattern, response, re.DOTALL)\n",
    "\n",
    "    for json_str in matches:\n",
    "        try:\n",
    "            return json.loads(json_str)  # Return the first valid JSON found\n",
    "        except json.JSONDecodeError:\n",
    "            continue  # If decoding fails, try the next match\n",
    "\n",
    "    # If no JSON blocks are found, try to parse the whole response\n",
    "    try:\n",
    "        return json.loads(response)\n",
    "    except json.JSONDecodeError:\n",
    "        return None  # Return None if no valid JSON is found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will help to extract the JSON data from the response Claude \n",
    "\n",
    "def extract_json_from_llm_response(response):\n",
    "    \"\"\"Extract JSON data from an LLM response that contains markdown code blocks.\"\"\"\n",
    "    json_pattern = r'```json\\s*(.*?)\\s*```'\n",
    "    matches = re.search(json_pattern, response, re.DOTALL)\n",
    "    \n",
    "    if matches:\n",
    "        json_str = matches.group(1)\n",
    "        return json.loads(json_str)\n",
    "    else:\n",
    "        # If no JSON in code blocks, try to parse the entire response\n",
    "        try:\n",
    "            return json.loads(response)\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product_eatanmol.com_September2020_CPA.json.gz, 0 - 1, title\n",
      "Product_eatanmol.com_September2020_CPA.json.gz, 0 - 2, description\n",
      "Product_eatanmol.com_September2020_CPA.json.gz, 0 - 3, publicationDate\n",
      "Product_eatanmol.com_September2020_CPA.json.gz, 0 - 4, category\n",
      "Product_eatanmol.com_September2020_CPA.json.gz, 0 - 5, price\n",
      "Product_eatanmol.com_September2020_CPA.json.gz, 0 - 6, currency\n",
      "Product_eatanmol.com_September2020_CPA.json.gz, 0 - 7, publisher\n",
      "Product_eatanmol.com_September2020_CPA.json.gz, 0 - 8, image\n",
      "Product_eatanmol.com_September2020_CPA.json.gz, 0 - 9, review\n",
      "Product_eatanmol.com_September2020_CPA.json.gz, 0 - 10, rating\n",
      "Product_eatanmol.com_September2020_CPA.json.gz, 0 - 11, startDateTime\n",
      "Movie_kingphim.net_September2020_CPA.json.gz, 0 - 1, title\n",
      "Movie_kingphim.net_September2020_CPA.json.gz, 0 - 2, startDateTime\n",
      "Movie_kingphim.net_September2020_CPA.json.gz, 0 - 3, endDateTime\n",
      "Movie_kingphim.net_September2020_CPA.json.gz, 0 - 4, rating\n",
      "Movie_kingphim.net_September2020_CPA.json.gz, 0 - 5, publisher\n",
      "Movie_kingphim.net_September2020_CPA.json.gz, 0 - 6, director\n",
      "Book_audubongalleries.com_September2020_CPA.json.gz, 0 - 1, author\n",
      "Book_audubongalleries.com_September2020_CPA.json.gz, 0 - 2, publisher\n",
      "Book_audubongalleries.com_September2020_CPA.json.gz, 0 - 3, price\n",
      "Book_audubongalleries.com_September2020_CPA.json.gz, 0 - 4, inStock\n",
      "No valid JSON found in response for file: Movie_movieon21.space_September2020_CPA.json.gz\n",
      "LocalBusiness_coregulatingtouch.com_September2020_CPA.json.gz, 0 - 1, name\n",
      "LocalBusiness_coregulatingtouch.com_September2020_CPA.json.gz, 0 - 2, credential\n",
      "LocalBusiness_coregulatingtouch.com_September2020_CPA.json.gz, 0 - 3, title\n",
      "Results have been saved to relationship_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Create a CSV file to store results\n",
    "csv_filename = \"relationship_results.csv\"\n",
    "with open(csv_filename, 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    # Write header\n",
    "    csv_writer.writerow(['filename', 'index_pair', 'relationship'])\n",
    "    \n",
    "    for file_name in selected_files: \n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        # Read file\n",
    "        df = pd.read_json(file_path, lines=True, compression=\"gzip\")\n",
    "        \n",
    "        # Count NaN values in each row\n",
    "        df['nan_count'] = df.isna().sum(axis=1)\n",
    "        \n",
    "        # Sort by NaN count (ascending)\n",
    "        df_sorted = df.sort_values('nan_count')\n",
    "        \n",
    "        # Take the top 10 rows with least NaNs\n",
    "        df_sampled = df_sorted.head(num_rows)\n",
    "        \n",
    "        # Drop the temporary nan_count column\n",
    "        df_sampled = df_sampled.drop('nan_count', axis=1)\n",
    "        \n",
    "        # Continue with your existing code\n",
    "        table_data = dataframe_to_string(df_sampled)\n",
    "        response = chain.run(table_data=table_data)\n",
    "        \n",
    "        # Extract JSON using the function we defined earlier\n",
    "        try:\n",
    "            relationships = extract_json_from_llm_response(response)\n",
    "            \n",
    "            if relationships:\n",
    "                for key, value in relationships.items():\n",
    "                    index_pair = key.replace(\"Index \", \"\")\n",
    "                    relationship_name = value.get(\"relationship\", \"Unknown\")\n",
    "                    \n",
    "                    # Print to console\n",
    "                    print(f\"{file_name}, {index_pair}, {relationship_name}\")\n",
    "                    \n",
    "                    # Write to CSV\n",
    "                    csv_writer.writerow([file_name, index_pair, relationship_name])\n",
    "            else:\n",
    "                print(f\"No valid JSON found in response for file: {file_name}\")\n",
    "                # You could write this error to the CSV as well\n",
    "                csv_writer.writerow([file_name, \"error\", \"No valid JSON found\"])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_name}: {str(e)}\")\n",
    "            # Write error to CSV\n",
    "            csv_writer.writerow([file_name, \"error\", str(e)])\n",
    "\n",
    "print(f\"Results have been saved to {csv_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prompt template\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"table_data\"],\n",
    "    template=\"\"\"\n",
    "You are a data annotation expert. Your task is to analyze tabular data \n",
    "and determine the most appropriate relationships between the first column and each of the remaining columns, \n",
    "using predefined labels. Ensure the output is structured in JSON format.\n",
    "\n",
    "## Candidate Labels:\n",
    "['publicationDate', 'price', 'language', 'currency', 'publisher', 'author', 'numberOfPages', 'isbn', 'format', 'genre', 'review',\n",
    " 'rating', 'image', 'description', 'startDateTime', 'endDateTime', 'locationName', 'performer', 'address', 'category', \n",
    " 'albumRuntime', 'time', 'city', 'country', 'region', 'postalCode', 'title', 'employer', 'day', 'director', 'starring', \n",
    " 'productionCompany', 'totalTracks', 'artist', 'album', 'birthPlace', 'birthDate', 'nationality', 'gender', 'deathDate', \n",
    " 'weight', 'colour', 'material', 'brand', 'manufacturer', 'releaseDate', 'cuisine', 'episodeNumber', 'televisionSeries']\n",
    "\n",
    "## **Table Data**\n",
    "{table_data}\n",
    "\n",
    "## **Task**\n",
    "- **Only analyze relationships between Column 1 as whole and each of the remaining columns as whole.**\n",
    "- Use the predefined Candidate labels for relationships.\n",
    "- Provide a structured JSON output in this format:\n",
    "\n",
    "```json\n",
    "{{\n",
    "  \"column 1 - column 2\": {{\n",
    "    \"relationship\": \"candidate_label\",\n",
    "    \"reasoning\": \"brief explanation of why this label applies\"\n",
    "  }},\n",
    "  \"column 1 - column 3\": {{\n",
    "    \"relationship\": \"candidate_label\",\n",
    "    \"reasoning\": \"brief explanation of why this label applies\"\n",
    "  }},\n",
    "  \"column 1 - column 4\": {{\n",
    "    \"relationship\": \"candidate_label\",\n",
    "    \"reasoning\": \"brief explanation of why this label applies\"\n",
    "  }}\n",
    "}}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_data=\"\"\"\n",
    "column 1,         column 2,             column 3,         column 4\n",
    "9789722539739,    A Cidade Perdida,     728,              2020-07-10\n",
    "9789722531924,    A Cúpula - livro 1,     704,              2016-04-08\n",
    "9789722527118,    Misery,               480,              2013-09-13\n",
    "9789722532457,    A Cúpula - Livro 2,     656,              2016-08-05\n",
    "9789722537636,    O Olho de Deus,        528,              2019-05-10\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\anaconda3\\envs\\langchain_env\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n",
      "c:\\Users\\Administrator\\anaconda3\\envs\\langchain_env\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# Initialize the local Llama 3_8b_4,4GB model via Ollama\n",
    "llm = Ollama(model=\"llama3:latest\")\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "response = chain.run(table_data=table_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided table data, I've analyzed the relationships between Column 1 and each of the remaining columns. Here's the output in JSON format:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"column 1 - column 2\": {\n",
      "    \"relationship\": \"title\",\n",
      "    \"reasoning\": \"The values in Column 2 appear to be book titles, which are closely related to the ISBNs in Column 1.\"\n",
      "  },\n",
      "  \"column 1 - column 3\": {\n",
      "    \"relationship\": \"numberOfPages\",\n",
      "    \"reasoning\": \"The values in Column 3 seem to represent the page counts of books corresponding to the ISBNs in Column 1.\"\n",
      "  },\n",
      "  \"column 1 - column 4\": {\n",
      "    \"relationship\": \"publicationDate\",\n",
      "    \"reasoning\": \"The values in Column 4 appear to be publication dates for the books corresponding to the ISBNs in Column 1.\"\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "In this analysis, I've inferred relationships between Column 1 (ISBN) and each of the remaining columns. Based on the data, it seems that:\n",
      "\n",
      "* Column 2 is related to book titles, which are often closely tied to their ISBNs.\n",
      "* Column 3 represents page counts for books, which can be an important attribute related to the ISBN.\n",
      "* Column 4 appears to contain publication dates for books, which could be relevant when considering their ISBNs.\n",
      "\n",
      "These relationships align with predefined candidate labels, and I've provided brief explanations for why each label applies.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the local qwen_2_7b_4,4gb model via Ollama\n",
    "llmqwen = Ollama(model=\"qwen2:latest\")\n",
    "chainqwen = LLMChain(llm=llmqwen, prompt=prompt_template)\n",
    "responseqwen = chainqwen.run(table_data=table_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"column 1 - column 2\": {\n",
      "    \"relationship\": \"title\",\n",
      "    \"reasoning\": \"Column 2 contains titles, which are likely the names of books or other items that can be uniquely identified by Column 1 (identifying numbers such as ISBNs)\"\n",
      "  },\n",
      "  \"column 1 - column 3\": {\n",
      "    \"relationship\": \"numberOfPages\",\n",
      "    \"reasoning\": \"Column 3 lists page counts for each item identified in Column 1, which is typically a characteristic of books or similar products\"\n",
      "  },\n",
      "  \"column 1 - column 4\": {\n",
      "    \"relationship\": \"publicationDate\",\n",
      "    \"reasoning\": \"Column 4 contains dates that correspond to the publication of items in Column 1, suggesting these are book release dates based on ISBNs provided\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(responseqwen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the local llama3.2:1b_1.3GB model via Ollama\n",
    "llmllamas = Ollama(model=\"llama3.2:1b\")\n",
    "chainllamas = LLMChain(llm=llmllamas, prompt=prompt_template)\n",
    "responsellamas = chainllamas.run(table_data=table_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine the most appropriate relationships between Column 1 and each of the remaining columns, using predefined labels, I will perform a correlation analysis on the table data. Here is the Python code that accomplishes this:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "from sklearn.feature_selection import SelectKBest\n",
      "from sklearn.feature_selection import f_regression\n",
      "\n",
      "# Load the tabular data into a Pandas DataFrame\n",
      "data = {\n",
      "    'column 1': ['9789722539739', '9789722531924', '9789722527118', '9789722532457', '9789722537636'],\n",
      "    'column 2': ['A Cidade Perdida', 'A Cúpula - livro 1', 'Misery', 'A Cúpula - Livro 2', 'O Olho de Deus'],\n",
      "    'column 3': [728, 704, 480, 656, 528],\n",
      "    'column 4': ['2020-07-10', '2016-04-08', '2013-09-13', '2016-08-05', '2019-05-10']\n",
      "}\n",
      "df = pd.DataFrame(data)\n",
      "\n",
      "# Define the Candidate labels\n",
      "candidate_labels = ['publicationDate', 'price', 'language', 'currency', 'publisher', 'author', 'numberOfPages', 'isbn', 'format', 'genre', 'review', \n",
      "                    'rating', 'image', 'description', 'startDateTime', 'endDateTime', 'locationName', 'performer', 'address', \n",
      "                    'category', 'albumRuntime', 'time', 'city', 'country', 'region', 'postalCode', 'title', 'employer', 'day', 'director', \n",
      "                    'starring', 'productionCompany', 'totalTracks', 'artist', 'album', 'birthPlace', 'birthDate', 'nationality', 'gender', \n",
      "                    'deathDate', 'weight', 'colour', 'material', 'brand', 'manufacturer', 'releaseDate', 'cuisine', 'episodeNumber', \n",
      "                    'televisionSeries']\n",
      "\n",
      "# Perform correlation analysis\n",
      "correlation_matrix = df.corr()\n",
      "\n",
      "# Select the top K features using f_regression from scikit-learn\n",
      "k = 3\n",
      "selector = SelectKBest(f_regression, k=k)\n",
      "\n",
      "# Get the selected features and their correlation with column 1\n",
      "selected_features = selector.fit_transform(df.drop('column 1', axis=1), df['column 1'])\n",
      "correlation_dataframe = pd.DataFrame(selected_features.T, columns=candidate_labels)\n",
      "correlation_df = pd.concat([df.drop(candidates=['column 1'], axis=1).reset_index(drop=True), correlation_dataframe], axis=1)\n",
      "\n",
      "# Print the selected features and their relationship to column 1\n",
      "print(\"Selected Features:\")\n",
      "print(correlation_df.head())\n",
      "```\n",
      "\n",
      "**Output:**\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"column 1 - column 2\": {\n",
      "        \"relationship\": \"candidate_label\",\n",
      "        \"reasoning\": \"A Cidade Perdida is related to A Cúpula - livro 1 because both are books published in Brazil\"\n",
      "    },\n",
      "    \"column 1 - column 3\": {\n",
      "        \"relationship\": \"candidate_label\",\n",
      "        \"reasoning\": \"Misery is a book that has been translated into multiple languages, which includes Portuguese\"\n",
      "    },\n",
      "    \"column 1 - column 4\": {\n",
      "        \"relationship\": \"candidate_label\",\n",
      "        \"reasoning\": \"O Olho de Deus is a Brazilian novel published in 2019 and has been translated into multiple languages\"\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "The selected features for Column 1 are 'publicationDate', 'price', 'language', 'currency', 'publisher', 'author', 'numberOfPages', 'isbn', 'format', 'genre', 'review', 'rating', 'image', 'description', 'startDateTime', 'endDateTime', 'locationName', 'performer', 'address', 'category', 'albumRuntime', 'time', 'city', 'country', 'region', 'postalCode', 'title', 'employer', 'day', 'director', 'starring', 'productionCompany', 'totalTracks', 'artist', 'album', 'birthPlace', 'birthDate', 'nationality', 'gender', 'deathDate', 'weight', 'colour', 'material', 'brand', 'manufacturer', 'releaseDate', 'cuisine', 'episodeNumber', 'televisionSeries'. These features have been selected because they are related to the content of Column 1.\n"
     ]
    }
   ],
   "source": [
    "print(responsellamas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the local deepseek-r1:1.5b model via Ollama\n",
    "llmdeepseek = Ollama(model=\"deepseek-r1:1.5b\")\n",
    "chaindeepseek = LLMChain(llm=llmdeepseek, prompt=prompt_template)\n",
    "responsedeepseek = chaindeepseek.run(table_data=table_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I'm trying to figure out how to assign the correct labels from the predefined list for each relationship between the first column and the other columns. The first column has numerical values like 9789722539739 and text values like \"A Cidade Perdida\". Let me go through each column one by one.\n",
      "\n",
      "Starting with Column 2, which is \"A Cidade Perdida\" – that's the name of a city. So when comparing it to the first number, I'm thinking about what makes sense. The number itself looks like an ISBN number. ISBNs are used for books and contain specific characters. So \"A Cidade Perdida\" should be \"isbn\". That seems straightforward.\n",
      "\n",
      "Next is Column 3 with \"728\", which is a small integer. Maybe it's the page count of something, but since we're looking at relationships to the first column as whole, I need a label that fits both together. \"PublicationDate\" is an option because publication dates often include numbers like this. So perhaps Column 3 relates to \"publicationDate\".\n",
      "\n",
      "Column 4 has \"2020-07-10\", which looks like a date. If the first column is about something published in 2020, then the relationship could be \"date\" or maybe \"language\". Wait, \"PublicationDate\" is an option and includes dates. So that might make more sense.\n",
      "\n",
      "Column 5 has \"O Olho de Deus\", which is a city title, similar to Column 2 but with a different name like \"The Other Place\". Following the same logic, this would be \"isbn\".\n",
      "\n",
      "So putting it all together:\n",
      "- Column 1 - Column 2: isbn\n",
      "- Column 1 - Column 3: publicationDate (since both are numerical representations of dates)\n",
      "- Column 1 - Column 4: date (if it's a release date) or maybe publicationDate if the year matches Column 1.\n",
      "- Column 1 - Column 5: isbn\n",
      "\n",
      "I think that makes sense. I should make sure each label fits with its respective data type correctly and see if any other candidate labels could be more appropriate, but the provided ones seem to cover all bases here.\n",
      "</think>\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"column 1 - column 2\": {\n",
      "    \"relationship\": \"isbn\",\n",
      "    \"reasoning\": \"Column 1 is a number representing an ISBN, while Column 2 is a city name which can be interpreted as an ISBN or book title.\"\n",
      "  },\n",
      "  \"column 1 - column 3\": {\n",
      "    \"relationship\": \"publicationDate\",\n",
      "    \"reasoning\": \"Column 1 and Column 3 are both numerical values related to dates. Column 1 could represent a publication date, so the relationship is likely 'publicationDate'.\"\n",
      "  },\n",
      "  \"column 1 - column 4\": {\n",
      "    \"relationship\": \"date\",\n",
      "    \"reasoning\": \"Column 1 includes years (2020) and months (July), which are dates. Column 4 could also be a release date, so the relationship is 'date'.'\n",
      "  },\n",
      "  \"column 1 - column 5\": {\n",
      "    \"relationship\": \"isbn\",\n",
      "    \"reasoning\": \"Column 1 is an ISBN number. Column 5 lists cities with similar structures, suggesting they are ISBNs.\"\n",
      "  }\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(responsedeepseek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the local llama3.2:3b model via Ollama\n",
    "llmllamas3b = Ollama(model=\"llama3.2:3b\")\n",
    "chainllamas3b = LLMChain(llm=llmllamas3b, prompt=prompt_template)\n",
    "responsellamas3b = chainllamas3b.run(table_data=table_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided table data and predefined labels, I have analyzed the relationships between Column 1 (ISBN) and each of the remaining columns. Here is the structured JSON output:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"column 1 - column 2\": {\n",
      "    \"relationship\": \"publisher\",\n",
      "    \"reasoning\": \"All values in this column are publisher names, matching the label 'publisher'\"\n",
      "  },\n",
      "  \"column 1 - column 3\": {\n",
      "    \"relationship\": \"price\",\n",
      "    \"reasoning\": \"The first three digits of each value represent a numerical price\"\n",
      "  },\n",
      "  \"column 1 - column 4\": {\n",
      "    \"relationship\": \"isbn\",\n",
      "    \"reasoning\": \"All values in this column are ISBNs, matching the label 'isbn'\"\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "In the above output:\n",
      "\n",
      "*   The relationship between Column 1 and Column 2 is identified as \"publisher\" because all the values in Column 2 match the predefined label for publisher names.\n",
      "*   The relationship between Column 1 and Column 3 is identified as \"price\" because the first three digits of each value represent a numerical price, matching the predefined label for prices.\n",
      "*   The relationship between Column 1 and Column 4 is also identified as \"isbn\" since all values in this column are ISBNs, which matches the predefined label.\n",
      "\n",
      "These relationships have been determined based on patterns or characteristics observed within the data.\n"
     ]
    }
   ],
   "source": [
    "print(responsellamas3b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
